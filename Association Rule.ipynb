{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#IMPORTING SPSS DATASET(.SAV) INTO PANDAS DATAFRAME\n",
    "import pyreadstat\n",
    "df, meta = pyreadstat.read_sav(\"Slovenia_COVID-19&Mental_Health.sav\",\n",
    "                               apply_value_formats=True,\n",
    "                               formats_as_category=True,\n",
    "                               formats_as_ordered_category=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#PREPARING CATEGORICAL DATA FOR TRANSACTION ENCODER\n",
    "import pandas as pd\n",
    "\n",
    "#01 Sex\n",
    "df['Sex'] = df['Sex'].apply(lambda x: 'Gender='+x)\n",
    "\n",
    "#02 Sex_Other\n",
    "del df['Sex_Other']\n",
    "\n",
    "#03 Age\n",
    "age_category = ['Age=Child(0-14)', 'Age=Young(14-24)', 'Age=Adults(24-64)', 'Age=Senior(64-100)']\n",
    "df['Age']=pd.cut(x=df['Age'], bins=[0,14,24,64,100],labels=age_category)\n",
    "\n",
    "#04 Education\n",
    "df['Education'] = df['Education'].apply(lambda x: 'Education='+x)\n",
    "\n",
    "#05 Income\n",
    "df['Income'].replace({'0 - 365 €': 'Income=Low(0-365€)',\n",
    "                      '365 - 550 €': 'Income=Low(365-550€)',\n",
    "                      '550 - 730 €': 'Income=Low(550-730€)',\n",
    "                      '730 - 920 €': 'Income=Medium(730-920€)',\n",
    "                      '920 - 1100 €': 'Income=Medium(920-1100€)',\n",
    "                      '1100 - 1280 €': 'Income=Medium(1100-1280€)',\n",
    "                      '1280 - 1460 €': 'Income=Medium(1280-1460€)',\n",
    "                      '1460 - 1830 €': 'Income=High(1460-1830€)',\n",
    "                      '1830 - 2200 €': 'Income=High(1830-2200€)',\n",
    "                      'nad 2200 €': 'Income=High(<2200€)'},\n",
    "                     inplace=True)\n",
    "\n",
    "\n",
    "#06 Residence\n",
    "df['Residence'] = df['Residence'].apply(lambda x: 'Residence='+x)\n",
    "\n",
    "#07 Region\n",
    "df['Region'] = df['Region'].apply(lambda x: 'Region='+x)\n",
    "\n",
    "#08 Household\n",
    "household_category = ['Household=1 person', 'Household=2 people', 'Household=3-6 people', 'Household=more than 6 people']\n",
    "df['Household']=pd.cut(x=df['Household'], bins=[0, 1, 2, 6, 100],labels=household_category)\n",
    "\n",
    "#09 Children\n",
    "children_category = ['Children=no child', 'Children=1 child', 'Children=2 or 3 childs', 'Children=more than 3 childs']\n",
    "df['Children']=pd.cut(x=df['Children'], bins=[-1,0, 1, 3, 100],labels=children_category)\n",
    "\n",
    "#10 Employment\n",
    "df['Employment'] = df['Employment'].apply(lambda x: 'Employment='+x)\n",
    "\n",
    "#11 Employment_Other\n",
    "del df['Employment_Other']\n",
    "\n",
    "#12 Changes_Work\n",
    "df['Changes_Work'] = df['Changes_Work'].apply(lambda x: 'Changes_Work='+x)\n",
    "\n",
    "#13 Changes_Work_Other\n",
    "del df['Changes_Work_Other']\n",
    "\n",
    "#14 Share_Wage\n",
    "Share_Wage_category = ['Share_Wage=Low(0-20%)', 'Share_Wage=Medium(20-50%)', 'Share_Wage=High(50-100%']\n",
    "df['Share_Wage']=pd.cut(x=df['Share_Wage'], bins=[-1,20, 50, 100],labels=Share_Wage_category)\n",
    "\n",
    "#15 Work_Quantity\n",
    "df['Work_Quantity'].replace({'I am working less than before': 'Work_Quantity=Work less than before',\n",
    "                      'I did not notice any changes regarding the quantity of my work': 'Work_Quantity=Work same as before',\n",
    "                      'I am working more than before': 'Work_Quantity=Work more than before'},\n",
    "                     inplace=True)\n",
    "\n",
    "#16 Increased_Risk\n",
    "df['Increased_Risk'] = df['Increased_Risk'].apply(lambda x: 'Increased_Risk='+x)\n",
    "\n",
    "#17 Increased_Risk_Household\n",
    "df['Increased_Risk_Household'] = df['Increased_Risk_Household'].apply(lambda x: 'Increased_Risk_Household='+x)\n",
    "\n",
    "#18 Job_Loss\n",
    "df['Job_Loss'] = df['Job_Loss'].apply(lambda x: 'Job_Loss='+x)\n",
    "\n",
    "#19 Job_Loss_Risk\n",
    "df['Job_Loss_Risk'] = df['Job_Loss_Risk'].apply(lambda x: 'Job_Loss_Risk='+x)\n",
    "\n",
    "#20 Vulnerable\n",
    "df['Vulnerable'] = df['Vulnerable'].apply(lambda x: 'Vulnerable='+x)\n",
    "\n",
    "#21 Vulnerable_Closeones\n",
    "df['Vulnerable_Closeones'] = df['Vulnerable_Closeones'].apply(lambda x: 'Vulnerable_Closeones='+x)\n",
    "\n",
    "#22 Infection\n",
    "df['Infection'] = df['Infection'].apply(lambda x: 'Infection='+x)\n",
    "\n",
    "#23 Infection_Signs\n",
    "df['Infection_Signs'] = df['Infection_Signs'].apply(lambda x: 'Infection_Signs='+x)\n",
    "\n",
    "#24 Infection_Probability\n",
    "df['Infection_Probability'] = df['Infection_Probability'].apply(lambda x: 'Infection_Probability='+x)\n",
    "\n",
    "#25 Fear_Level\n",
    "fear_level_category = ['Fear_Level=Low(0-20%)', 'Fear_Level=Medium(20-50%)', 'Fear_Level=High(50-100%']\n",
    "df['Fear_Level']=pd.cut(x=df['Fear_Level'], bins=[-1,20, 50, 100],labels=fear_level_category)\n",
    "\n",
    "#26 News_Following\n",
    "df['News_Following'] = df['News_Following'].apply(lambda x: 'News_Following='+x)\n",
    "\n",
    "#27 Following_Measures\n",
    "df['Following_Measures'] = df['Following_Measures'].apply(lambda x: 'Following_Measures='+x)\n",
    "\n",
    "#28 Daily_Changes\n",
    "df['Daily_Changes'] = df['Daily_Changes'].apply(lambda x: 'Daily_Changes='+x)\n",
    "\n",
    "#29 Shopping\n",
    "df['Shopping'] = df['Shopping'].apply(lambda x: 'Shopping='+x)\n",
    "\n",
    "#30-35 STAI_S_\n",
    "del df['STAI_S_1R']\n",
    "del df['STAI_S_2']\n",
    "del df['STAI_S_3']\n",
    "del df['STAI_S_4R']\n",
    "del df['STAI_S_5R']\n",
    "del df['STAI_S_6']\n",
    "\n",
    "#36 STAI_State_Score\n",
    "STAI_State_Score_category = ['STAI_ANXIETY=Low(0-8)', 'STAI_ANXIETY=Medium(8-16)', 'STAI_ANXIETY=High(16-24)']\n",
    "df['STAI_State_Score']=pd.cut(x=df['STAI_State_Score'], bins=[0,8,16,24],labels=STAI_State_Score_category)\n",
    "\n",
    "#37-42 STAI_T_\n",
    "del df['STAI_T_1R']\n",
    "del df['STAI_T_2']\n",
    "del df['STAI_T_3R']\n",
    "del df['STAI_T_4']\n",
    "del df['STAI_T_5']\n",
    "del df['STAI_trait_skupno']\n",
    "\n",
    "#43-47 WHO5_\n",
    "del df['WHO5_1']\n",
    "del df['WHO5_2']\n",
    "del df['WHO5_3']\n",
    "del df['WHO5_4']\n",
    "del df['WHO5_5']\n",
    "\n",
    "#48 WHO5_Score\n",
    "WHO5_Score_category = ['WHO5_Life_Quality=Worst(0-5)',\n",
    "                       'WHO5_Life_Quality=Lower_Middle(6-10)',\n",
    "                       'WHO5_Life_Quality=Middle(11-15)',\n",
    "                       'WHO5_Life_Quality=Upper_Middle(16-20)',\n",
    "                       'WHO5_Life_Quality=Best(21-25)']\n",
    "df['WHO5_Score']=pd.cut(x=df['WHO5_Score'], bins=[-1,5,10,15,20,25],labels=WHO5_Score_category)\n",
    "\n",
    "#49-56 DJG_\n",
    "del df['DJG1']\n",
    "del df['DJG2']\n",
    "del df['DJG3']\n",
    "del df['DJG4']\n",
    "del df['DJG5']\n",
    "del df['DJG6']\n",
    "del df['DJG_EL']\n",
    "del df['DJG_SL']\n",
    "\n",
    "#57 DJG_Score\n",
    "DJG_Score_category = ['DJG_Score=Not Lonely(0-3)',\n",
    "                      'DJG_Score=Extremely Lonely(<3)']\n",
    "df['DJG_Score']=pd.cut(x=df['DJG_Score'], bins=[-1,3,11],labels=DJG_Score_category)\n",
    "\n",
    "#58-60 UCLA_\n",
    "del df['UCLA1']\n",
    "del df['UCLA2']\n",
    "del df['UCLA3']\n",
    "\n",
    "#61 UCLA_Score\n",
    "UCLA_Score_category = ['UCLA_Score=Not Lonely(0–2)',\n",
    "                      'UCLA_Score=Moderate Loneliness(3-8)',\n",
    "                      'UCLA_Score=Severe Loneliness(9-10)',\n",
    "                      'UCLA_Score=Very Severe Loneliness (11)']\n",
    "df['UCLA_Score']=pd.cut(x=df['UCLA_Score'], bins=[-1,2,8,10,11],labels=UCLA_Score_category)\n",
    "\n",
    "#62 UCLA_Additional\n",
    "del df['UCLA_Additional']\n",
    "\n",
    "#63-66 String (SENTIMENT ANALYSIS?)\n",
    "del df['Biggest_Worry']\n",
    "del df['Wishes_Psychologists']\n",
    "del df['Positive_Changes']\n",
    "del df['Other']\n",
    "\n",
    "#67 C_across_rutine\n",
    "df['C_across_rutine'].replace({'I did not come across': 'C_across_rutine=No',\n",
    "                               'I came across': 'C_across_rutine=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#68 C_across_hanging_out\n",
    "df['C_across_hanging_out'].replace({'I did not come across': 'C_across_hanging_out=No',\n",
    "                               'I came across': 'C_across_hanging_out=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#69 C_across_health\n",
    "df['C_across_health'].replace({'I did not come across': 'C_across_health=No',\n",
    "                               'I came across': 'C_across_health=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#70 C_across_humor\n",
    "df['C_across_humor'].replace({'I did not come across': 'C_across_humor=No',\n",
    "                               'I came across': 'C_across_humor=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#71 C_across_mindful\n",
    "df['C_across_mindful'].replace({'I did not come across': 'C_across_mindful=No',\n",
    "                               'I came across': 'C_across_mindful=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#72 C_across_activity\n",
    "df['C_across_activity'].replace({'I did not come across': 'C_across_activity=No',\n",
    "                               'I came across': 'C_across_activity=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#73 C_across_info\n",
    "df['C_across_info'].replace({'I did not come across': 'C_across_info=No',\n",
    "                               'I came across': 'C_across_info=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#74 C_across_media\n",
    "df['C_across_media'].replace({'I did not come across': 'C_across_media=No',\n",
    "                               'I came across': 'C_across_media=Yes'},\n",
    "                              inplace=True)\n",
    "\n",
    "#75 C_across_total\n",
    "del df['C_across_total']\n",
    "\n",
    "#76 Execution_rutine\n",
    "df['Execution_rutine'].replace({'I do not execute': 'Execution_rutine=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_rutine=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_rutine=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_rutine=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#77 Execution_hanging_out\n",
    "df['Execution_hanging_out'].replace({'I do not execute': 'Execution_hanging_out=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_hanging_out=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_hanging_out=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_hanging_out=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#78 Execution_health\n",
    "df['Execution_health'].replace({'I do not execute': 'Execution_health=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_health=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_health=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_health=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#79 Execution_humor\n",
    "df['Execution_humor'].replace({'I do not execute': 'Execution_humor=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_humor=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_humor=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_humor=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#80 Execution_mindful\n",
    "df['Execution_mindful'].replace({'I do not execute': 'Execution_mindful=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_mindful=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_mindful=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_mindful=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#81 Execution_activity\n",
    "df['Execution_activity'].replace({'I do not execute': 'Execution_activity=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_activity=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_activity=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_activity=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#82 Execution_info\n",
    "df['Execution_info'].replace({'I do not execute': 'Execution_info=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_info=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_info=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_info=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#83 Execution_media\n",
    "df['Execution_media'].replace({'I do not execute': 'Execution_media=I do not execute',\n",
    "                               'I execute, but it does not help me': 'Execution_media=I execute, but it does not help me',\n",
    "                               'I execute, it helps a little bit': 'Execution_media=I execute, it helps',\n",
    "                               'I execute, it helps a lot': 'Execution_media=I execute, it helps'},\n",
    "                              inplace=True)\n",
    "\n",
    "#84 Execution_total\n",
    "del df['Execution_total']\n",
    "\n",
    "#85 Media_channel\n",
    "df['Media_channel'] = df['Media_channel'].apply(lambda x: 'Media_channel='+x)\n",
    "\n",
    "#86 Media_channel_Other\n",
    "del df['Media_channel_Other']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#CONVERTING DATASET INTO TRANSACTIONAL TRUE/FALSE DATAFRAME FOR APRIORI\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "dataset =  df.T.apply(lambda x: x.dropna().tolist()).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_ary=te.fit(dataset).transform(dataset)\n",
    "df2 = pd.DataFrame(te_ary, columns=te.columns_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#EXPORTING PREPARED DATASET AND TRANS-ENCODED DATASET\n",
    "from pathlib import Path\n",
    "filepath1 = Path('C:\\python\\prepared_dataset.csv')\n",
    "filepath1.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(filepath1)\n",
    "\n",
    "filepath2 = Path('C:\\python\\encoded_dataset.csv')\n",
    "filepath2.parent.mkdir(parents=True, exist_ok=True)\n",
    "df2.to_csv(filepath2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#FINDING FREQUENT ITEM SETS USING APRIORI\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "frequent_itemsets = apriori(df2 , min_support=0.6 , use_colnames=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                              antecedents  \\\n0                 (C_across_activity=Yes)   \n1                     (Age=Adults(24-64))   \n2              (C_across_hanging_out=Yes)   \n3                     (Age=Adults(24-64))   \n4                   (C_across_health=Yes)   \n...                                   ...   \n29449    (C_across_info=Yes, Job_Loss=No)   \n29450  (Vulnerable=No, C_across_info=Yes)   \n29451        (Vulnerable=No, Job_Loss=No)   \n29452                (Infection_Signs=No)   \n29453                     (Vulnerable=No)   \n\n                                             consequents  antecedent support  \\\n0                                    (Age=Adults(24-64))            0.858521   \n1                                (C_across_activity=Yes)            0.733119   \n2                                    (Age=Adults(24-64))            0.929260   \n3                             (C_across_hanging_out=Yes)            0.733119   \n4                                    (Age=Adults(24-64))            0.926045   \n...                                                  ...                 ...   \n29449  (C_across_health=Yes, Infection_Signs=No, C_ac...            0.845659   \n29450  (C_across_health=Yes, Infection_Signs=No, C_ac...            0.794212   \n29451  (C_across_health=Yes, Infection_Signs=No, C_ac...            0.816720   \n29452  (C_across_health=Yes, C_across_hanging_out=Yes...            0.871383   \n29453  (C_across_health=Yes, Infection_Signs=No, C_ac...            0.874598   \n\n       consequent support   support  confidence      lift  leverage  \\\n0                0.733119  0.636656    0.741573  1.011532  0.007258   \n1                0.858521  0.636656    0.868421  1.011532  0.007258   \n2                0.733119  0.681672    0.733564  1.000607  0.000414   \n3                0.929260  0.681672    0.929825  1.000607  0.000414   \n4                0.733119  0.684887    0.739583  1.008818  0.005986   \n...                   ...       ...         ...       ...       ...   \n29449            0.694534  0.614148    0.726236  1.045645  0.026809   \n29450            0.717042  0.614148    0.773279  1.078430  0.044665   \n29451            0.729904  0.614148    0.751969  1.030230  0.018021   \n29452            0.688103  0.614148    0.704797  1.024261  0.014547   \n29453            0.678457  0.614148    0.702206  1.035005  0.020771   \n\n       conviction  \n0        1.032714  \n1        1.075241  \n2        1.001670  \n3        1.008039  \n4        1.024823  \n...           ...  \n29449    1.115800  \n29450    1.248048  \n29451    1.088960  \n29452    1.056551  \n29453    1.079751  \n\n[29454 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>antecedents</th>\n      <th>consequents</th>\n      <th>antecedent support</th>\n      <th>consequent support</th>\n      <th>support</th>\n      <th>confidence</th>\n      <th>lift</th>\n      <th>leverage</th>\n      <th>conviction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(C_across_activity=Yes)</td>\n      <td>(Age=Adults(24-64))</td>\n      <td>0.858521</td>\n      <td>0.733119</td>\n      <td>0.636656</td>\n      <td>0.741573</td>\n      <td>1.011532</td>\n      <td>0.007258</td>\n      <td>1.032714</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(Age=Adults(24-64))</td>\n      <td>(C_across_activity=Yes)</td>\n      <td>0.733119</td>\n      <td>0.858521</td>\n      <td>0.636656</td>\n      <td>0.868421</td>\n      <td>1.011532</td>\n      <td>0.007258</td>\n      <td>1.075241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(C_across_hanging_out=Yes)</td>\n      <td>(Age=Adults(24-64))</td>\n      <td>0.929260</td>\n      <td>0.733119</td>\n      <td>0.681672</td>\n      <td>0.733564</td>\n      <td>1.000607</td>\n      <td>0.000414</td>\n      <td>1.001670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(Age=Adults(24-64))</td>\n      <td>(C_across_hanging_out=Yes)</td>\n      <td>0.733119</td>\n      <td>0.929260</td>\n      <td>0.681672</td>\n      <td>0.929825</td>\n      <td>1.000607</td>\n      <td>0.000414</td>\n      <td>1.008039</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(C_across_health=Yes)</td>\n      <td>(Age=Adults(24-64))</td>\n      <td>0.926045</td>\n      <td>0.733119</td>\n      <td>0.684887</td>\n      <td>0.739583</td>\n      <td>1.008818</td>\n      <td>0.005986</td>\n      <td>1.024823</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29449</th>\n      <td>(C_across_info=Yes, Job_Loss=No)</td>\n      <td>(C_across_health=Yes, Infection_Signs=No, C_ac...</td>\n      <td>0.845659</td>\n      <td>0.694534</td>\n      <td>0.614148</td>\n      <td>0.726236</td>\n      <td>1.045645</td>\n      <td>0.026809</td>\n      <td>1.115800</td>\n    </tr>\n    <tr>\n      <th>29450</th>\n      <td>(Vulnerable=No, C_across_info=Yes)</td>\n      <td>(C_across_health=Yes, Infection_Signs=No, C_ac...</td>\n      <td>0.794212</td>\n      <td>0.717042</td>\n      <td>0.614148</td>\n      <td>0.773279</td>\n      <td>1.078430</td>\n      <td>0.044665</td>\n      <td>1.248048</td>\n    </tr>\n    <tr>\n      <th>29451</th>\n      <td>(Vulnerable=No, Job_Loss=No)</td>\n      <td>(C_across_health=Yes, Infection_Signs=No, C_ac...</td>\n      <td>0.816720</td>\n      <td>0.729904</td>\n      <td>0.614148</td>\n      <td>0.751969</td>\n      <td>1.030230</td>\n      <td>0.018021</td>\n      <td>1.088960</td>\n    </tr>\n    <tr>\n      <th>29452</th>\n      <td>(Infection_Signs=No)</td>\n      <td>(C_across_health=Yes, C_across_hanging_out=Yes...</td>\n      <td>0.871383</td>\n      <td>0.688103</td>\n      <td>0.614148</td>\n      <td>0.704797</td>\n      <td>1.024261</td>\n      <td>0.014547</td>\n      <td>1.056551</td>\n    </tr>\n    <tr>\n      <th>29453</th>\n      <td>(Vulnerable=No)</td>\n      <td>(C_across_health=Yes, Infection_Signs=No, C_ac...</td>\n      <td>0.874598</td>\n      <td>0.678457</td>\n      <td>0.614148</td>\n      <td>0.702206</td>\n      <td>1.035005</td>\n      <td>0.020771</td>\n      <td>1.079751</td>\n    </tr>\n  </tbody>\n</table>\n<p>29454 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINDING ASSOCIATION RULES\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "rules = association_rules(frequent_itemsets , metric=\"confidence\" , min_threshold=0.7)\n",
    "rules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#DISPLAYING ASSOCIATION RULES IN SCATTERPLOT\n",
    "# df.plot.scatter(x = rules['support'], y = rules['confidence'], c='red');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}